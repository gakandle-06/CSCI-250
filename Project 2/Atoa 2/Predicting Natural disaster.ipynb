{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a13427-df39-4e0f-8f2e-683144a73c33",
   "metadata": {},
   "source": [
    "**Computer science 250 Project** \n",
    "\n",
    "**Name**: **Dayyan Fundi** \n",
    "    \n",
    "**Partner Name**: **Gavela Maculuve**\n",
    "    \n",
    "**Topic**: **Predicting Disaster Response Time Using Machine Learning: A Random Forest Approach Using the Global Disaster Response Dataset (2018–2024)**\n",
    "\n",
    "**Research Question**: **Can we predict how long it will take for responding agencies to arrive after a disaster, based on event characteristics such as type, severity, and location?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0ea5c-9701-4fe8-b3c0-c9194394b592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Section 1: Project outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24ed07-2339-4e65-a51b-6bfa45b8acce",
   "metadata": {},
   "source": [
    "# Predicting Disaster Response Time Using Machine Learning  \n",
    "### Global Disaster Response Dataset (2018–2024)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Abstract  \n",
    "This project analyzes global disaster events from 2018–2024 and builds a machine learning model to **predict disaster response time** using Random Forest Regression. The model uses disaster type, severity, fatalities, affected population, and location to estimate how long it takes responders to arrive at a disaster site.  \n",
    "We also build:  \n",
    "- A **Linear Regression model** as a baseline  \n",
    "- A **K-Means Clustering model** to reveal patterns in disasters  \n",
    "\n",
    "Random Forest provides the best performance and identifies the most important predictors of response delay.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Introduction  \n",
    "Disasters vary in severity, type, and location — all influencing how fast governments and organizations respond. Predicting response time can help emergency systems allocate resources more efficiently.  \n",
    "\n",
    "This project uses machine learning to:  \n",
    "- Predict disaster response times  \n",
    "- Identify factors influencing delays  \n",
    "- Discover natural groups (clusters) in global disaster events  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Research Question  \n",
    "**Can we accurately predict how long it will take for responders to arrive after a disaster, based on event characteristics?**\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Dataset Summary  \n",
    "Dataset fields include:  \n",
    "- *disaster_type*  \n",
    "- *location_country*  \n",
    "- *severity_level*  \n",
    "- *fatalities*  \n",
    "- *people_affected*  \n",
    "- *economic_loss*  \n",
    "- *date*  \n",
    "- *response_time_hours* (target variable)  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Methodology Overview  \n",
    "### **Models used:**  \n",
    "- Linear Regression (baseline)  \n",
    "- Random Forest Regressor (main model)  \n",
    "- K-Means clustering (unsupervised pattern discovery)  \n",
    "\n",
    "### **Steps:**  \n",
    "1. Import dataset  \n",
    "2. Clean missing data  \n",
    "3. Feature engineering  \n",
    "4. Build baseline model  \n",
    "5. Build Random Forest model  \n",
    "6. Evaluate models  \n",
    "7. Build clustering model  \n",
    "8. Visualize clusters  \n",
    "9. Interpret results  \n",
    "10. Conclusion  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Expected Outputs  \n",
    "- MAE, RMSE, R² for both models  \n",
    "- Feature importance graph  \n",
    "- Cluster visualization  \n",
    "- Final insights & summary  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1faae1d-d5d2-492a-890b-6614412dbe2f",
   "metadata": {},
   "source": [
    "# Section 2: python code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8f534-bcb2-4675-969b-e4baeb7b0261",
   "metadata": {},
   "source": [
    "**2.1. Importing important librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ea3d32d-9894-40db-91c9-e3ae8a54d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 1. IMPORT LIBRARIES\n",
    "# ---------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305b330-548c-4c37-a870-024ae81b8316",
   "metadata": {},
   "source": [
    "**2.2. Loading dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4fe767d-b815-4e1f-b2a7-75ebcb9e2115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>severity_index</th>\n",
       "      <th>casualties</th>\n",
       "      <th>economic_loss_usd</th>\n",
       "      <th>response_time_hours</th>\n",
       "      <th>aid_amount_usd</th>\n",
       "      <th>response_efficiency_score</th>\n",
       "      <th>recovery_days</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>5.99</td>\n",
       "      <td>111</td>\n",
       "      <td>7934365.71</td>\n",
       "      <td>15.62</td>\n",
       "      <td>271603.79</td>\n",
       "      <td>83.21</td>\n",
       "      <td>67</td>\n",
       "      <td>-30.613</td>\n",
       "      <td>-122.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-23</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Extreme Heat</td>\n",
       "      <td>6.53</td>\n",
       "      <td>100</td>\n",
       "      <td>8307648.99</td>\n",
       "      <td>5.03</td>\n",
       "      <td>265873.81</td>\n",
       "      <td>96.18</td>\n",
       "      <td>55</td>\n",
       "      <td>10.859</td>\n",
       "      <td>-159.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>India</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>1.55</td>\n",
       "      <td>22</td>\n",
       "      <td>765136.99</td>\n",
       "      <td>32.54</td>\n",
       "      <td>49356.49</td>\n",
       "      <td>60.40</td>\n",
       "      <td>22</td>\n",
       "      <td>0.643</td>\n",
       "      <td>-160.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Extreme Heat</td>\n",
       "      <td>4.55</td>\n",
       "      <td>94</td>\n",
       "      <td>1308251.31</td>\n",
       "      <td>7.83</td>\n",
       "      <td>237512.88</td>\n",
       "      <td>86.41</td>\n",
       "      <td>47</td>\n",
       "      <td>-33.547</td>\n",
       "      <td>30.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>United States</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>3.80</td>\n",
       "      <td>64</td>\n",
       "      <td>2655864.36</td>\n",
       "      <td>21.90</td>\n",
       "      <td>188910.69</td>\n",
       "      <td>72.81</td>\n",
       "      <td>42</td>\n",
       "      <td>-19.170</td>\n",
       "      <td>-117.137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        country disaster_type  severity_index  casualties  \\\n",
       "0  2021-01-31         Brazil    Earthquake            5.99         111   \n",
       "1  2018-12-23         Brazil  Extreme Heat            6.53         100   \n",
       "2  2020-08-10          India     Hurricane            1.55          22   \n",
       "3  2022-09-15      Indonesia  Extreme Heat            4.55          94   \n",
       "4  2022-09-28  United States      Wildfire            3.80          64   \n",
       "\n",
       "   economic_loss_usd  response_time_hours  aid_amount_usd  \\\n",
       "0         7934365.71                15.62       271603.79   \n",
       "1         8307648.99                 5.03       265873.81   \n",
       "2          765136.99                32.54        49356.49   \n",
       "3         1308251.31                 7.83       237512.88   \n",
       "4         2655864.36                21.90       188910.69   \n",
       "\n",
       "   response_efficiency_score  recovery_days  latitude  longitude  \n",
       "0                      83.21             67   -30.613   -122.557  \n",
       "1                      96.18             55    10.859   -159.194  \n",
       "2                      60.40             22     0.643   -160.978  \n",
       "3                      86.41             47   -33.547     30.350  \n",
       "4                      72.81             42   -19.170   -117.137  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"global_disaster_response_2018_2024.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a81f1af9-b8c4-4363-9dc8-f1e11bb0f25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 50000\n",
      "Number of columns: 12\n",
      "\n",
      "Dataset Shape: (50000, 12)\n",
      "\n",
      "Column Names:\n",
      "['date', 'country', 'disaster_type', 'severity_index', 'casualties', 'economic_loss_usd', 'response_time_hours', 'aid_amount_usd', 'response_efficiency_score', 'recovery_days', 'latitude', 'longitude']\n",
      "\n",
      "Basic Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   date                       50000 non-null  object \n",
      " 1   country                    50000 non-null  object \n",
      " 2   disaster_type              50000 non-null  object \n",
      " 3   severity_index             50000 non-null  float64\n",
      " 4   casualties                 50000 non-null  int64  \n",
      " 5   economic_loss_usd          50000 non-null  float64\n",
      " 6   response_time_hours        50000 non-null  float64\n",
      " 7   aid_amount_usd             50000 non-null  float64\n",
      " 8   response_efficiency_score  50000 non-null  float64\n",
      " 9   recovery_days              50000 non-null  int64  \n",
      " 10  latitude                   50000 non-null  float64\n",
      " 11  longitude                  50000 non-null  float64\n",
      "dtypes: float64(7), int64(2), object(3)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 2.1 DATASET OVERVIEW\n",
    "# ---------------------------------------------\n",
    "\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "print(\"\\nBasic Info:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bec09-62c0-4c2a-80bc-9dc3145bc5c1",
   "metadata": {},
   "source": [
    "# Section 3: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43093cee-46d2-4da2-b432-6f80e8d966b2",
   "metadata": {},
   "source": [
    "**3.1. Cleaning missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bedcf58-dc0a-4f7b-bbcb-201fa93f9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows missing the target variable\n",
    "df = df.dropna(subset=[\"response_time_hours\"])\n",
    "\n",
    "# Fill numeric missing values\n",
    "num_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "# Fill categorical missing values\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adedcd96-8569-4011-8254-f0911890962e",
   "metadata": {},
   "source": [
    "**3.2. Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c31d67e5-510b-4b62-a2a0-f33460e75c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date into components\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"day_of_week\"] = df[\"date\"].dt.weekday\n",
    "\n",
    "# Choose features\n",
    "features = [\n",
    "    \"disaster_type\", \"country\", \"severity_index\",\n",
    "    \"casualties\", \"economic_loss_usd\",\n",
    "    \"year\", \"month\", \"day_of_week\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"response_time_hours\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f53570-241d-4874-93b6-dfd6de1a2762",
   "metadata": {},
   "source": [
    "**3.3. Train/ Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6e2af165-e5eb-4b0c-bb28-2150dfd6d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 3.3 TRAIN/TEST SPLIT\n",
    "# ---------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61835b7b-765c-4a01-8091-ce5e14ebf42f",
   "metadata": {},
   "source": [
    "**3.4. Preprocessing Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4e7f8cd-4490-4116-a2d4-b608a8635e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 3.4 PREPROCESSING PIPELINE (Corrected)\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Updated feature lists based on your dataset\n",
    "numeric_features = [\n",
    "    \"casualties\",\n",
    "    \"economic_loss_usd\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day_of_week\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"disaster_type\",\n",
    "    \"country\",\n",
    "    \"severity_index\"\n",
    "]\n",
    "\n",
    "# Build the preprocessing transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8814e2-8b91-4f1d-b124-153c3350f483",
   "metadata": {},
   "source": [
    "# Section 4: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241556d-b309-4cb1-8e19-ba18463f5a1e",
   "metadata": {},
   "source": [
    "**4.1 Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55ce31a9-07c5-4549-a404-acf19d3a9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MAE: 3.865416366913522\n",
      "Linear Regression RMSE: 4.763779131483152\n",
      "Linear Regression R2: 0.7261584928806271\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 4.1 LINEAR REGRESSION (Corrected)\n",
    "# ---------------------------------------------\n",
    "\n",
    "linreg_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_model.fit(X_train, y_train)\n",
    "y_pred_lr = linreg_model.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression MAE:\", mean_absolute_error(y_test, y_pred_lr))\n",
    "print(\"Linear Regression RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lr)))\n",
    "print(\"Linear Regression R2:\", r2_score(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2485c2f-c4ae-43b4-a2ed-d393703d5466",
   "metadata": {},
   "source": [
    "**4.2 Random Forest Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f308bda-b330-4ca7-8c07-3093c0cbf196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 4.2 RANDOM FOREST REGRESSOR (Corrected)\n",
    "# ---------------------------------------------\n",
    "\n",
    "rf_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"Random Forest RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "print(\"Random Forest R2:\", r2_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35702096-f751-4b23-b401-946ad1eb5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 4.2 RANDOM FOREST REGRESSOR (MAIN MODEL)\n",
    "# ---------------------------------------------\n",
    "\n",
    "rf_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"Random Forest RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "print(\"Random Forest R2:\", r2_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fa118-ea92-4621-bca9-38d929f5b908",
   "metadata": {},
   "source": [
    "**4.3 Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed92ab6-df92-48a6-9c04-43a95907774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# 4.3 FEATURE IMPORTANCE (Corrected)\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Get fitted OneHotEncoder\n",
    "encoder = rf_model.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
    "\n",
    "# Get the encoded categorical names\n",
    "onehot_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine numeric + categorical names\n",
    "feature_names = numeric_features + list(onehot_names)\n",
    "\n",
    "# Extract random forest importances\n",
    "importances = rf_model.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "# Create DataFrame\n",
    "fi_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False).head(20)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=fi_df, x=\"importance\", y=\"feature\")\n",
    "plt.title(\"Top Feature Importances — Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6bd0f-ef7a-4136-a477-d7e581f1b9ed",
   "metadata": {},
   "source": [
    "# Section 5: Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d208bad-0ff9-4cf8-9cf6-fbadc61e8210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace49b31-fc31-4fbe-8a1f-efb685a42e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ecca00-b1e1-4f4a-b09f-57e2999f2d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80326153-d1a1-4764-9210-1b87c5590f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8e805-745b-4a3d-9478-4fa8c17f665c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
